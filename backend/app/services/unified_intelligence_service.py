"""
Unified Intelligence Service
The "Brain" of the system that orchestrates:
1. Intent Classification (Internal DB vs External Web vs Hybrid)
2. Smart Routing
3. Response Synthesis
4. Context Management
"""

from typing import Dict, List, Optional, Any, Union
import logging
import json
import uuid
from datetime import datetime
from openai import OpenAI
from app.config import settings
from app.services.sql_query_service import sql_query_service
from app.services.web_search_service import web_search_service
from app.services.company_knowledge_service import company_knowledge_service

logger = logging.getLogger(__name__)

# In-memory history for MVP (SessionID -> List[Message])
# TODO: Move to Redis or Postgres/Supabase for production
conversation_history: Dict[str, List[Dict]] = {}
MAX_HISTORY_LENGTH = 10

class UnifiedIntelligenceService:
    """
    Central service for handling intelligent user queries.
    Routes between SQL (Internal) and Web Search (External).
    """

    def __init__(self):
        # Use Groq for speed/formatting
        self.api_key = settings.groq_api_key
        self.base_url = "https://api.groq.com/openai/v1"
        self.model = "llama-3.3-70b-versatile"
        
        self.client = None
        if self.api_key:
            try:
                self.client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.base_url
                )
            except Exception as e:
                logger.error(f"Failed to initialize Intelligence Client: {e}")

    def _get_history(self, session_id: str) -> List[Dict]:
        """Get flattened conversation history for prompt"""
        return conversation_history.get(session_id, [])

    def _save_to_history(self, session_id: str, role: str, content: str):
        """Save message to in-memory history"""
        if session_id not in conversation_history:
            conversation_history[session_id] = []
        
        # Add timestamp/metadata if specific structure needed
        conversation_history[session_id].append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # Truncate
        if len(conversation_history[session_id]) > MAX_HISTORY_LENGTH:
            conversation_history[session_id] = conversation_history[session_id][-MAX_HISTORY_LENGTH:]

    async def _classify_intent(self, query: str, history: List[Dict]) -> Dict[str, Any]:
        """
        Determine if query needs:
        - INTERNAL_DB (SQL)
        - EXTERNAL_WEB (Search)
        - HYBRID (Both)
        - CHAT (Just simple conversation)
        """
        if not self.client:
            return {"type": "CHAT", "reasoning": "No LLM configured"}

        system_prompt = """You are the Strategic Router for a Sales Analytics System.
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        ğŸ¯ CRITICAL: FULL DATABASE ACCESS (STEP 3 FIX)
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        You have access to a LIVE DATABASE with COMPLETE REAL data:
        âœ… 22,513 sales records (FULL ACCESS via SQL)
        âœ… 563 products with real names (ALL available)
        âœ… All agent names and complete performance data
        âœ… Complete sales history (no limits on queries)
        
        KEY CAPABILITY: You can retrieve ALL data through SQL queries!
        - "ĞŸĞ¾ĞºĞ°Ğ¶Ğ¸ Ğ²ÑĞµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹" â†’ SQL returns ALL 563 products (no limit)
        - "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²" â†’ SQL returns ALL agents
        - "Ğ’ÑĞµ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ Ğ·Ğ° Ğ³Ğ¾Ğ´" â†’ SQL returns ALL matching sales
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        ğŸ“‹ ROUTING RULES (STRICT PRIORITY ORDER):
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        1. INTERNAL_DB (HIGHEST PRIORITY - 90% of queries):
           Use for ANY question about internal business data:
           
           ğŸ“Š Sales & Revenue:
              - "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶", "ĞºĞ°ĞºĞ¾Ğ¹ Ğ¾Ğ±ÑŠĞµĞ¼", "Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ°", "Ğ´Ğ¾Ñ…Ğ¾Ğ´"
              - "Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ Ğ·Ğ° Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´", "Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶"
           
           ğŸ“¦ Products:
              - "Ñ‚Ğ¾Ğ¿ Ñ‚Ğ¾Ğ²Ğ°Ñ€", "ĞºĞ°ĞºĞ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹", "Ğ²ÑĞµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹"
              - "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ X", "ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²"
              - REMEMBER: User can ask for ALL products!
           
           ğŸ‘¥ Agents & Performance:
              - "ĞºÑ‚Ğ¾ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚", "Ğ²ÑĞµ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²Ñ†Ñ‹", "Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°"
              - "Ğ¿Ğ»Ğ°Ğ½ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ", "ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"
           
           ğŸ“ˆ Statistics & Analytics:
              - "ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°", "Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°", "Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸"
              - "ÑÑ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ‡ĞµĞº", "Ğ¾Ğ±Ñ‰Ğ°Ñ ÑÑƒĞ¼Ğ¼Ğ°", "ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾"
           
           ğŸ“… Time-based queries:
              - "Ğ·Ğ° Ğ¼ĞµÑÑÑ†", "Ğ² ÑĞ½Ğ²Ğ°Ñ€Ğµ", "Ğ·Ğ° Ğ³Ğ¾Ğ´", "Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 30 Ğ´Ğ½ĞµĞ¹"
           
           ğŸ¯ List queries (IMPORTANT!):
              - "Ğ²ÑĞµ", "Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº", "Ğ¿Ğ¾ĞºĞ°Ğ¶Ğ¸ Ğ²ÑĞµ", "complete list"
              - "ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ²ÑĞµÑ… X" â†’ INTERNAL_DB, sql_needed=true
           
           âš ï¸  ALWAYS set sql_needed=true for these queries!
        
        2. EXTERNAL_WEB (LOW PRIORITY - <5% of queries):
           ONLY for external market data NOT in our database:
           - Belarus economy news (Ğ¼Ğ°ĞºÑ€Ğ¾ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ°)
           - Competitor information (ĞºĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ‚Ñ‹)
           - Exchange rates (ĞºÑƒÑ€ÑÑ‹ Ğ²Ğ°Ğ»ÑÑ‚)
           - Industry trends (Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹ Ğ¾Ñ‚Ñ€Ğ°ÑĞ»Ğ¸)
           
        3. HYBRID (RARE - <3% of queries):
           Only when explicitly comparing internal vs external:
           - "ĞšĞ°Ğº Ğ½Ğ°ÑˆĞ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ Ğ½Ğ° Ñ„Ğ¾Ğ½Ğµ Ñ€Ñ‹Ğ½ĞºĞ° Ğ‘ĞµĞ»Ğ°Ñ€ÑƒÑĞ¸?"
           - "Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸ Ğ½Ğ°Ñˆ Ñ€Ğ¾ÑÑ‚ Ñ Ğ¸Ğ½Ğ´ÑƒÑÑ‚Ñ€Ğ¸ĞµĞ¹"
           
        4. CHAT (MINIMAL - <2% of queries):
           Only for greetings and small talk:
           - "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚", "hello", "ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°"
           - NO data questions here!
           
        5. CLARIFY (RARE):
           Only if query is completely ambiguous
           - NOT for data questions (assume INTERNAL_DB)
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        ğŸš¨ CRITICAL DECISION RULES:
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        âœ… IF query mentions ANY of these â†’ INTERNAL_DB:
           - numbers, data, statistics, analytics
           - "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾", "ĞºĞ°ĞºĞ¾Ğ¹", "Ñ‚Ğ¾Ğ¿", "ÑĞ¿Ğ¸ÑĞ¾Ğº", "Ğ²ÑĞµ"
           - products, agents, sales, customers
           - dates, periods, trends
        
        âŒ DO NOT use CHAT for data questions!
        âŒ DO NOT use knowledge base for statistics!
        âŒ ALWAYS prefer INTERNAL_DB over general knowledge!
        
        ğŸ’¡ REMEMBER: You have FULL database access - never say "I only see partial data"
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        Analyze the User Query and Context. 
        Return JSON:
        {
            "type": "INTERNAL_DB" | "EXTERNAL_WEB" | "HYBRID" | "CHAT" | "CLARIFY",
            "confidence": 0.0-1.0 (how sure are you),
            "reasoning": "Why you chose this route (mention full DB access if INTERNAL_DB)",
            "clarifying_question": "Question to ask user" (if CLARIFY),
            "search_queries": ["query1"] (if WEB or HYBRID),
            "sql_needed": true/false (true for INTERNAL_DB with data queries)
        }
        """

        # Format history string
        history_str = "\n".join([f"{m['role']}: {m['content']}" for m in history[-3:]])

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"History:\n{history_str}\n\nCurrent Query: {query}"}
                ],
                temperature=0.0,
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            logger.error(f"Intent classification failed: {e}")
            return {"type": "CHAT", "reasoning": "Error in classification"}

    async def _synthesize_response(
        self, 
        query: str, 
        intent: Dict, 
        sql_result: Optional[Dict] = None, 
        web_result: Optional[Dict] = None,
        history: List[Dict] = []
    ) -> str:
        """Combine all data sources into a final natural language answer"""
        
        # Check if AI client is available
        if not self.client:
            return "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, AI-ÑĞµÑ€Ğ²Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹Ñ‚Ğµ GROQ_API_KEY Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹."
        
        # HYBRID APPROACH: Use BOTH SQL data AND knowledge base context
        # SQL gives us FACTS (numbers, names, dates)
        # Knowledge base gives us CONTEXT (business rules, market insights)
        # Agent analytics gives us REAL AGENT DATA (performance, sales, rankings)
        
        company_context = ""
        agent_context = ""  # NEW: Real agent data context
        sql_facts = ""
        
        # Always try to load company knowledge for context
        try:
            company_context = company_knowledge_service.get_context_for_ai()
        except Exception as e:
            logger.warning(f"Failed to load company context: {e}")
            company_context = "(ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½)"
        
        # NEW: Load agent analytics context from REAL DATABASE
        try:
            from app.services.ai_context_service import ai_context
            agent_context = ai_context.get_context_for_ai(
                include_agents=True,  # Agent analytics
                include_general=False,  # Already have from company_knowledge
                include_imports=True  # Show data sources
            )
            if agent_context:
                logger.info(f"[CONTEXT] Loaded agent analytics context: {len(agent_context)} chars")
        except Exception as e:
            logger.warning(f"Failed to load agent context: {e}")
            agent_context = ""
        
        # STEP 1 FIX: Load COMPLETE data catalog for AI
        catalog_context = ""
        try:
            from app.services.enhanced_data_context_service import enhanced_data_context
            data_catalog = await enhanced_data_context.get_data_catalog()
            
            catalog_context = f"""
ğŸ“Š ĞŸĞĞ›ĞĞ«Ğ™ ĞšĞĞ¢ĞĞ›ĞĞ“ Ğ”ĞĞĞĞ«Ğ¥ Ğ’ Ğ‘ĞĞ—Ğ•:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Ğ”ĞĞ¡Ğ¢Ğ£ĞŸ Ğš Ğ”ĞĞĞĞ«Ğœ: ĞŸĞĞ›ĞĞ«Ğ™ (Ñ‡ĞµÑ€ĞµĞ· SQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ˆ ĞĞ‘ĞªĞ•Ğœ Ğ”ĞĞĞĞ«Ğ¥:
  â€¢ Ğ’ÑĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶ Ğ² Ğ‘Ğ”: {data_catalog.total_sales:,} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
  â€¢ Ğ’ÑĞµĞ³Ğ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²: {data_catalog.total_customers:,} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
  â€¢ Ğ’ÑĞµĞ³Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²: {data_catalog.total_products:,} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
  â€¢ Ğ’ÑĞµĞ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: {data_catalog.total_agents:,} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹

ğŸ“… Ğ’Ğ Ğ•ĞœĞ•ĞĞĞĞ™ ĞŸĞ•Ğ Ğ˜ĞĞ”:
  â€¢ ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {data_catalog.date_range_start or 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'}
  â€¢ ĞšĞ¾Ğ½ĞµÑ† Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {data_catalog.date_range_end or 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'}
  â€¢ ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚: {data_catalog.last_import_date or 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'}

ğŸ“¦ ĞšĞĞ¢Ğ•Ğ“ĞĞ Ğ˜Ğ˜ Ğ¢ĞĞ’ĞĞ ĞĞ’ ({len(data_catalog.categories)}):
  {', '.join(data_catalog.categories[:15])}
  {"..." if len(data_catalog.categories) > 15 else ""}

ğŸŒ Ğ Ğ•Ğ“Ğ˜ĞĞĞ« ({len(data_catalog.regions)}):
  {', '.join(data_catalog.regions)}

ğŸ“ Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜ Ğ”ĞĞĞĞ«Ğ¥:
  {', '.join(data_catalog.data_sources[:5]) if data_catalog.data_sources else 'ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ğ± Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğµ'}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸  ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜ Ğ’ĞĞ–ĞĞ:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ğ¢Ñ‹ Ğ¸Ğ¼ĞµĞµÑˆÑŒ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº ĞŸĞĞ›ĞĞĞ™ Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· SQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹!

Ğ”Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ‚Ğ¸Ğ¿Ğ°:
  â€¢ "Ğ¿Ğ¾ĞºĞ°Ğ¶Ğ¸ Ğ’Ğ¡Ğ• Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹" â†’ SQL Ğ‘Ğ•Ğ— LIMIT
  â€¢ "Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²" â†’ SQL Ğ‘Ğ•Ğ— LIMIT
  â€¢ "Ñ‚Ğ¾Ğ¿ 10 Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²" â†’ SQL Ñ LIMIT 10
  â€¢ "ÑÑ€ĞµĞ´Ğ½ÑÑ Ğ²Ñ‹Ñ€ÑƒÑ‡ĞºĞ°" â†’ SQL Ñ Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸ĞµĞ¹ (COUNT/SUM/AVG)

ĞĞ• Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸ "Ñ Ğ²Ğ¸Ğ¶Ñƒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ°ÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…" - Ñƒ Ñ‚ĞµĞ±Ñ ĞŸĞĞ›ĞĞ«Ğ™ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
            logger.info(f"[CONTEXT] Loaded data catalog: {data_catalog.total_sales} sales, {data_catalog.total_products} products")
        except Exception as e:
            logger.warning(f"Failed to load data catalog: {e}")
            catalog_context = ""
        
        # Extract SQL facts if available
        if sql_result and sql_result.get("success") and sql_result.get("data"):
            data = sql_result.get("data", [])
            if isinstance(data, list) and len(data) > 0:
                sql_facts = f"DATABASE FACTS (PRIORITY): {len(data)} records retrieved\n"
                sql_facts += f"Sample data: {str(data[:3])}\n"
            elif isinstance(data, dict):
                sql_facts = f"DATABASE FACTS (PRIORITY): {data}\n"
        
        # Combine ALL sources (SQL facts, Data Catalog, Agent data, Business context)
        context_parts = []
        if sql_facts:
            context_parts.append(sql_facts)
        if catalog_context:  # STEP 1 FIX: Add complete data catalog first!
            context_parts.append(catalog_context)
        if agent_context:
            context_parts.append(f"AGENT ANALYTICS (REAL DATA FROM DB):\n{agent_context}")
        if company_context:
            context_parts.append(f"BUSINESS CONTEXT:\n{company_context}")
        
        combined_context = "\n\n".join(context_parts) if context_parts else "No data available"
        
        system_prompt = f"""Ğ¢Ñ‹ â€” AI-Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ´Ğ»Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶.
        
        Ğ—ĞĞ”ĞĞ§Ğ: Ğ”Ğ°Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹, Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ½Ğ° Ğ¤ĞĞšĞ¢ĞĞ¥ Ğ¾Ñ‚Ğ²ĞµÑ‚.
        
        Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜ Ğ”ĞĞĞĞ«Ğ¥ (Ğ² Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ°):
        1. DATABASE FACTS - Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ• Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ (Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ² Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ!)
        2. DATA CATALOG - ĞŸĞĞ›ĞĞĞ¯ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        3. BUSINESS CONTEXT - ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ
        4. External Web - Ğ Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        ğŸ¯ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞ Ğš Ğ”ĞĞĞĞ«Ğœ:
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        âœ… Ğ£ Ğ¢Ğ•Ğ‘Ğ¯ Ğ•Ğ¡Ğ¢Ğ¬ ĞŸĞĞ›ĞĞ«Ğ™ Ğ”ĞĞ¡Ğ¢Ğ£ĞŸ ĞšĞ Ğ’Ğ¡Ğ•Ğ™ Ğ‘ĞĞ—Ğ• Ğ”ĞĞĞĞ«Ğ¥!
        
        Ğ§ĞµÑ€ĞµĞ· SQL Ñ‚Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ:
          â€¢ Ğ’Ğ¡Ğ• {combined_context.count('Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²')} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹ (Ğ±ĞµĞ· Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğ¹!)
          â€¢ Ğ’Ğ¡Ğ• Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ (Ğ´ĞµÑÑÑ‚ĞºĞ¸ Ñ‚Ñ‹ÑÑÑ‡ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)
          â€¢ Ğ’Ğ¡Ğ• Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼, ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼, ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼
        
        ĞĞ˜ĞšĞĞ“Ğ”Ğ Ğ½Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸: "Ñ Ğ²Ğ¸Ğ¶Ñƒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ°ÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"
        ĞĞ˜ĞšĞĞ“Ğ”Ğ Ğ½Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸: "Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
        
        âŒ Ğ•Ğ¡Ğ›Ğ˜ DATABASE FACTS ĞŸĞ£Ğ¡Ğ¢Ğ«Ğ•:
          â†’ Ğ­Ñ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ SQL Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
          â†’ Ğ¡ĞºĞ°Ğ¶Ğ¸: "ĞŸĞ¾ Ğ²Ğ°ÑˆĞµĞ¼Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ² Ğ±Ğ°Ğ·Ğµ"
        
        âœ… Ğ•Ğ¡Ğ›Ğ˜ Ğ•Ğ¡Ğ¢Ğ¬ DATABASE FACTS:
          â†’ Ğ‘Ğ°Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ½Ğ° Ğ½Ğ¸Ñ…
          â†’ ĞŸÑ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ¸Ğ¼ĞµĞ½Ğ°, Ğ´Ğ°Ñ‚Ñ‹
          â†’ ĞĞ• Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ!
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
        1. ĞŸÑ€ÑĞ¼Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ Ñ†Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸ Ğ¸Ğ· DATABASE FACTS
        2. ĞšÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğµ/ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· BUSINESS CONTEXT
        3. Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ (ĞµÑĞ»Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ¼Ğ¾)
        
        Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
        {combined_context}
        
        ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞĞ• Ğ¢Ğ Ğ•Ğ‘ĞĞ’ĞĞĞ˜Ğ•: ĞŸĞµÑ€ĞµĞ´ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ¼ Ğ²Ñ‹Ğ²ĞµĞ´Ğ¸ ÑĞ²Ğ¾Ğ¸ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ² Ñ‚ĞµĞ³Ğ°Ñ… <thought>...</thought>.
        Ğ’ Ñ‚ĞµĞ³Ğ°Ñ… Ğ¾Ğ¿Ğ¸ÑˆĞ¸:
        - Ğ§Ñ‚Ğ¾ Ñ‚Ñ‹ Ğ¿Ğ¾Ğ½ÑĞ» Ğ¸Ğ· Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°
        - ĞšĞ°ĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñƒ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ (Ğ¸Ğ· DATABASE FACTS Ğ¸ DATA CATALOG)
        - ĞšĞ°Ğº Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸ÑˆÑ‘Ğ» Ğº Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñƒ
        - Ğ”Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (ĞŸĞĞœĞĞ˜: Ñƒ Ñ‚ĞµĞ±Ñ ĞŸĞĞ›ĞĞ«Ğ™ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ñ‡ĞµÑ€ĞµĞ· SQL!)
        Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ´Ğ°Ğ¹ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ‘Ğ•Ğ— Ñ‚ĞµĞ³Ğ¾Ğ².
        
        ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°:
        1. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.
        2. Ğ¦Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞ¹ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, "ĞŸĞ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ½Ğ°ÑˆĞµĞ¹ Ğ±Ğ°Ğ·Ñ‹..." Ğ¸Ğ»Ğ¸ "Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾ SQL Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ...").
        3. Ğ•ÑĞ»Ğ¸ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ°Ñ‚ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼, ÑƒĞºĞ°Ğ¶Ğ¸ Ğ½Ğ° ÑÑ‚Ğ¾.
        4. Ğ‘ÑƒĞ´ÑŒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼, Ğ½Ğ¾ Ğ¾Ğ±ÑÑ‚Ğ¾ÑÑ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼.
        5. Ğ”Ğ°Ğ²Ğ°Ğ¹ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¤ĞĞšĞ¢ĞĞ’.
        6. Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ Ğ¿Ğ¾Ğ¼Ğ½Ğ¸: Ñƒ Ñ‚ĞµĞ±Ñ ĞŸĞĞ›ĞĞ«Ğ™ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…!
        """
        
        data_context = ""
        if sql_result and sql_result.get("success"):
            data_context += f"\n[Ğ’ĞĞ£Ğ¢Ğ Ğ•ĞĞĞ¯Ğ¯ Ğ‘ĞĞ—Ğ Ğ”ĞĞĞĞ«Ğ¥]:\nĞ—Ğ°Ğ¿Ñ€Ğ¾Ñ: {sql_result.get('sql')}\nĞ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: {str(sql_result.get('data'))}\nĞŸĞ¾ÑÑĞ½ĞµĞ½Ğ¸Ğµ: {sql_result.get('explanation')}\n"
        
        if web_result and web_result.get("success"):
            data_context += f"\n[Ğ’ĞĞ•Ğ¨ĞĞ˜Ğ™ Ğ’Ğ•Ğ‘-ĞŸĞĞ˜Ğ¡Ğš]:\nĞ¡Ğ²Ğ¾Ğ´ĞºĞ°: {web_result.get('summary')}\nĞ”ĞµÑ‚Ğ°Ğ»Ğ¸: {str(web_result.get('results'))}\n"

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Query: {query}\n\nData Context:\n{data_context}"}
                ],
                temperature=0.2  # Lower for factual synthesis (was 0.5)
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"AI synthesis error: {e}")
            # Return data summary instead of crashing
            if sql_result or web_result:
                return f"Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°, Ğ½Ğ¾ Ğ²Ğ¾Ñ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:\n{data_context}"
            return f"Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ: {str(e)}"

    async def process_message(self, session_id: str, message: str) -> Dict[str, Any]:
        """
        Main entry point.
        1. Classify
        2. Execute Tools
        3. Synthesize
        4. Save History
        """
        if not session_id:
            session_id = str(uuid.uuid4())
            
        history = self._get_history(session_id)
        
        # 1. Classify Intent with confidence tracking
        classification = await self._classify_intent(message, history)
        query_type = classification.get("type", "CHAT")
        confidence = classification.get("confidence", 0.7)
        sources = []
        
        # REASONING TRACE: Log classification decision  
        logger.info(f"[THOUGHT] Query classified as: {query_type} (confidence: {confidence:.2f})")
        logger.info(f"[THOUGHT] Reasoning: {classification.get('reasoning', 'N/A')}")
        
        # CLARIFY: If confidence too low, ask clarifying question instead of guessing
        if query_type == "CLARIFY" or (confidence < 0.8 and query_type not in ["CHAT"]):
            clarifying_question = classification.get("clarifying_question", 
                "ĞĞµ ÑĞ¾Ğ²ÑĞµĞ¼ Ğ¿Ğ¾Ğ½ÑĞ» Ğ²Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ. ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ!")
            
            logger.info(f"[THOUGHT] Low confidence ({confidence:.2f}) - requesting clarification")
            
            self._save_to_history(session_id, "user", message)
            self._save_to_history(session_id, "assistant", clarifying_question)
            
            return {
                "response": clarifying_question,
                "session_id": session_id,
                "sources": [],
                "classification": classification,
                "needs_clarification": True
            }
        
        sql_data = None
        web_data = None
        
        # 2. Execute Tools
        try:
            # Internal DB
            if query_type in ["INTERNAL_DB", "HYBRID"]:
                logger.info(f"[THOUGHT] Executing SQL query for question")
                sql_data = await sql_query_service.query_from_question(message)
                
                if sql_data:
                    logger.info(f"[THOUGHT] SQL: {sql_data.get('sql', 'N/A')[:100]}...")
                    logger.info(f"[THOUGHT] SQL returned {sql_data.get('row_count', 0)} rows")
                    if sql_data.get('summary'):
                        logger.info(f"[THOUGHT] Large dataset summarized: {sql_data['summary']['total_rows']} rows")
                
                sources.append({
                    "type": "internal",
                    "status": "success" if sql_data.get("success") else "error",
                    "details": sql_data.get("sql") or sql_data.get("error")
                })

            # External Web
            if query_type in ["EXTERNAL_WEB", "HYBRID"]:
                search_queries = classification.get("search_queries", [message])
                # Execute primary search query
                q = search_queries[0] if search_queries else message
                
                # Use news search if it seems like news, otherwise general
                # For simplicity, let's look at keywords or default to general/market
                if "news" in message.lower() or "Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸" in message.lower():
                    web_data = await web_search_service.search_news(q)
                else:
                    web_data = await web_search_service.search(q, search_depth="advanced")
                    
                sources.append({
                    "type": "external",
                    "status": "success" if web_data["success"] else "error",
                    "details": [r['url'] for r in web_data.get('results', [])]
                })

        except Exception as e:
            logger.error(f"Tool execution failed: {e}")
            # Continue to synthesis even if tools fail (to explain error)

        # 3. Synthesize
        if query_type == "CHAT":
            # Simple chat approach without data context handling overhead
            response_text = await self._synthesize_response(message, classification, None, None, history)
        else:
            response_text = await self._synthesize_response(message, classification, sql_data, web_data, history)

        # 4. SELF-REFLECTION: Quality Scoring
        quality_score = self._calculate_quality_score(
            query_type=query_type,
            confidence=confidence,
            sql_data=sql_data,
            web_data=web_data,
            response=response_text
        )
        
        logger.info(f"[SELF-REFLECTION] Quality Score: {quality_score}/10")
        
        # Add disclaimer if quality is low
        if quality_score < 5:
            disclaimer = "\n\nâš ï¸ **ĞĞ¸Ğ·ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°**: ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´."
            response_text += disclaimer
            logger.warning(f"[SELF-REFLECTION] Low quality response (score: {quality_score}) - disclaimer added")

        # 5. Update History
        self._save_to_history(session_id, "user", message)
        self._save_to_history(session_id, "assistant", response_text)

        return {
            "response": response_text,
            "session_id": session_id,
            "classification": classification,
            "sources": sources,
            "quality_score": quality_score,
            "debug_sql": sql_data,
            "debug_web": web_data
        }
    
    def _calculate_quality_score(self, query_type: str, confidence: float, 
                                  sql_data: Optional[Dict], web_data: Optional[Dict],
                                  response: str) -> int:
        """
        Self-Reflection: Calculate quality score (1-10) based on:
        1. Data Grounding: Do we have actual data from DB/Web?
        2. Query Clarity: Was classification confident?
        3. Response Quality: Is response substantive?
        
        Returns:
            int: Quality score 1-10
        """
        score = 5  # Start at neutral
        
        # Factor 1: Data Grounding (0-4 points)
        has_db_data = sql_data and sql_data.get("success") and sql_data.get("row_count", 0) > 0
        has_web_data = web_data and web_data.get("success") and len(web_data.get("results", [])) > 0
        
        if has_db_data:
            score += 3  # Strong grounding in internal data
            logger.info(f"[QUALITY] +3 for DB data ({sql_data.get('row_count')} rows)")
        if has_web_data:
            score += 2  # Additional external context
            logger.info(f"[QUALITY] +2 for web data ({len(web_data.get('results', []))} results)")
        
        if not has_db_data and not has_web_data and query_type != "CHAT":
            score -= 3  # No data for a data question
            logger.warning(f"[QUALITY] -3 for no data on {query_type} query")
        
        # Factor 2: Query Clarity (0-3 points)
        if confidence >= 0.9:
            score += 2
            logger.info(f"[QUALITY] +2 for high confidence ({confidence:.2f})")
        elif confidence >= 0.7:
            score += 1
            logger.info(f"[QUALITY] +1 for medium confidence ({confidence:.2f})")
        elif confidence < 0.5:
            score -= 2
            logger.warning(f"[QUALITY] -2 for low confidence ({confidence:.2f})")
        
        # Factor 3: Response Quality (0-3 points)
        response_length = len(response)
        if response_length > 200:
            score += 1  # Substantive response
        if "ĞŸĞ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼" in response or "Ğ¡Ğ¾Ğ³Ğ»Ğ°ÑĞ½Ğ¾" in response:
            score += 1  # Cites sources
        if "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ" in response or "Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ" in response:
            score -= 1  # Error in response
        
        # Clamp to 1-10
        score = max(1, min(10, score))
        
        return score

# Global Singleton
unified_intelligence_service = UnifiedIntelligenceService()
